{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Py35",
      "language": "python",
      "name": "py35"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "AISec_Phishing_Logistic_Regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiLSYUSo4Qvl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import *\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings \n",
        "warnings.simplefilter('ignore')\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVecDCzc4Qvo"
      },
      "source": [
        "cols = ['having_IP_Address','URL_Length','Shortining_Service','having_At_Symbol','double_slash_redirecting','Prefix_Suffix','having_Sub_Domain','SSLfinal_State','Domain_registeration_length','Favicon','port','HTTPS_token','Request_URL','URL_of_Anchor','Links_in_tags','SFH','Submitting_to_email','Abnormal_URL','Redirect','on_mouseover','RightClick','popUpWidnow','Iframe','age_of_domain','DNSRecord','web_traffic','Page_Rank','Google_Index','Links_pointing_to_page','Statistical_report','Result']\n",
        "path = '/content/phishing_dataset.csv'\n",
        "\n",
        "phishing_dataset = pd.read_csv( path, delimiter=',', dtype=np.int32,names=cols)\n",
        "\n",
        "samples = phishing_dataset.iloc[:,:-1]\n",
        "targets = phishing_dataset.iloc[:, -1]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_samples, testing_samples, training_targets, testing_targets = train_test_split(\n",
        "         samples, targets, test_size=0.2, random_state=7)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0A52vBU4Qv7"
      },
      "source": [
        "# Check the LR coef to undrstand Features Importance\n",
        "def calc_feat_imp(model, samples):\n",
        "    \n",
        "    coef = model.coef_[0]\n",
        "    col = list(samples.columns)\n",
        "    col_dict = dict(list(zip(col,coef)))\n",
        "    feat_sort =  sorted(col_dict.items(), key=lambda kv: abs(kv[1]), reverse=True)\n",
        "    return feat_sort"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Oq_aqX4Qvt"
      },
      "source": [
        "# Train and return Accuracy\n",
        "def train_score(model, data, threshold=0.5):\n",
        "    \n",
        "    acc = []\n",
        "    model.fit(data[0], data[1])\n",
        "    \n",
        "    for index in [0,2]:\n",
        "        pred = model.predict_proba(data[index],)\n",
        "        pred = np.where(pred[:,1] > threshold, 1, -1)\n",
        "        accuracy = 100.0 * accuracy_score(data[index+1], pred)\n",
        "        acc.append(accuracy)\n",
        "    feat_imp = calc_feat_imp(model, data[0])\n",
        "    \n",
        "    return acc, feat_imp"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl6S4PIq4Qv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f0e31f-4b1a-4161-d8b3-d6766707239c"
      },
      "source": [
        "# Print score\n",
        "model = LogisticRegression()\n",
        "acc, feat_sort = train_score(model, [training_samples, training_targets, testing_samples, testing_targets])\n",
        "\n",
        "print(acc[0], acc[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92.48077792853913 93.71325192220714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9_htvnmhb3v"
      },
      "source": [
        "## Let's create the degree-2 poly features of top 20 featutes to handle Interaction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZxhPx3kDUi5"
      },
      "source": [
        "# Polynomial Linear Regresion \n",
        "def poly_feat(x,deg):\n",
        "    from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "    poly = PolynomialFeatures(degree = deg) \n",
        "    x = pd.DataFrame(poly.fit_transform(x), columns=poly.get_feature_names(samples.columns)) \n",
        "\n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AfN2B99qasd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f96a1a-759a-4d66-8a52-c100d0c4dbc0"
      },
      "source": [
        "d = 2\n",
        "feat_cnt = 20\n",
        "col_top_cnt = [ elem[0] for elem in feat_sort ][:feat_cnt]\n",
        "\n",
        "# Select top \"col_top_cnt\" Features\n",
        "training_samples, testing_samples  = training_samples.loc[:,col_top_cnt], testing_samples.loc[:,col_top_cnt]\n",
        "\n",
        "# Generate Polynomial Features\n",
        "training_samples, testing_samples  = poly_feat(training_samples, d), poly_feat(testing_samples, d) # testing_samples.shape\n",
        "\n",
        "# Print score\n",
        "THRESHOLD = 0.425\n",
        "acc, feat_sort = train_score(model, [training_samples, training_targets, testing_samples, testing_targets], threshold=THRESHOLD)\n",
        "print(acc[0], acc[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.31886024423338 95.16056083220262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVq5y12xmfVf",
        "outputId": "525efd2d-0654-4cad-9423-fab362bc1ce5"
      },
      "source": [
        "# Top Features to reduce Feature count without impacting accuracy\n",
        "feat_cnt = 140\n",
        "col_top_cnt = [ elem[0] for elem in feat_sort ][:feat_cnt]\n",
        "training_samples, testing_samples  = training_samples.loc[:,col_top_cnt], testing_samples.loc[:,col_top_cnt]\n",
        "\n",
        "# Print score\n",
        "acc, feat_sort = train_score(model, [training_samples, training_targets, testing_samples, testing_targets]) #testing_samples.shape[0]*(1-.9502487562189054)\n",
        "\n",
        "print(acc[0], acc[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.27363184079603 95.02487562189054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0vj2YjXr-JD"
      },
      "source": [
        "## **Hyper-parameter tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBnUdMm7sCiU"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Create regularization penalty space\n",
        "penalty = ['l1', 'l2']\n",
        "# Create regularization hyperparameter space\n",
        "C = np.linspace(0,0.1,20)\n",
        "# Create hyperparameter options\n",
        "hyperparameters = dict(C=C, penalty=penalty)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q179npvqz3SP"
      },
      "source": [
        "# Create grid search using 5-fold cross validation\n",
        "clf = GridSearchCV(model, hyperparameters, cv=5, verbose=0)\n",
        "# Fit grid search\n",
        "grid_clf = clf.fit(training_samples, training_targets)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_Ic5QHXz3J_",
        "outputId": "9489ca7d-0ef2-4aaf-dc38-f5f2e0c1bc25"
      },
      "source": [
        "# Print score\n",
        "acc, feat_sort = train_score(model, [training_samples, training_targets, testing_samples, testing_targets])\n",
        "\n",
        "print(acc[0], acc[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.27363184079603 95.02487562189054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AEEIk4mq2of4",
        "outputId": "5280ba00-8f6b-4011-c633-5a022f896dde"
      },
      "source": [
        "'''No benefit of Hyper-parm tuning'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'No benefit of Hyper-parm tuning'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}